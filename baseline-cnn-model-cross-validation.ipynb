{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa13c2cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T03:22:26.505730Z",
     "iopub.status.busy": "2025-11-20T03:22:26.505479Z",
     "iopub.status.idle": "2025-11-20T03:22:35.731128Z",
     "shell.execute_reply": "2025-11-20T03:22:35.730322Z"
    },
    "papermill": {
     "duration": 9.231116,
     "end_time": "2025-11-20T03:22:35.732592",
     "exception": false,
     "start_time": "2025-11-20T03:22:26.501476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sea\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import joblib \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from mne.viz.topomap import _prepare_topomap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132446de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T03:22:35.738791Z",
     "iopub.status.busy": "2025-11-20T03:22:35.738193Z",
     "iopub.status.idle": "2025-11-20T03:22:35.741676Z",
     "shell.execute_reply": "2025-11-20T03:22:35.741144Z"
    },
    "papermill": {
     "duration": 0.007393,
     "end_time": "2025-11-20T03:22:35.742751",
     "exception": false,
     "start_time": "2025-11-20T03:22:35.735358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 3126\n",
    "EPOCHS = 20\n",
    "GRID_SIZE = 32\n",
    "TIME_WINDOW = (0.1, 0.5)\n",
    "N_TIME_SLICES = 16\n",
    "LEARNING_RATE = 7.5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45629f2a",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-11-20T03:22:35.748016Z",
     "iopub.status.busy": "2025-11-20T03:22:35.747810Z",
     "iopub.status.idle": "2025-11-20T03:22:35.756589Z",
     "shell.execute_reply": "2025-11-20T03:22:35.756072Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.012526,
     "end_time": "2025-11-20T03:22:35.757519",
     "exception": false,
     "start_time": "2025-11-20T03:22:35.744993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)               \n",
    "    np.random.seed(seed)            \n",
    "    torch.manual_seed(seed)         \n",
    "    torch.cuda.manual_seed(seed)    \n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5590ce6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T03:22:35.762723Z",
     "iopub.status.busy": "2025-11-20T03:22:35.762545Z",
     "iopub.status.idle": "2025-11-20T03:22:35.770166Z",
     "shell.execute_reply": "2025-11-20T03:22:35.769625Z"
    },
    "papermill": {
     "duration": 0.011458,
     "end_time": "2025-11-20T03:22:35.771195",
     "exception": false,
     "start_time": "2025-11-20T03:22:35.759737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MEGDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Converts MEG epochs into interpolated 2D topographic images.\n",
    "    Each trial => tensor of shape (n_time_slices, grid_size, grid_size)\n",
    "\n",
    "    Inputs:\n",
    "        X: ndarray (M_trials, C_channels, T_timepoints)\n",
    "        y: labels (M_trials,)\n",
    "        epochs: MNE epochs object (contains time info and sensor positions)\n",
    "        time_window: start and end of the period you care about (t0 and t1, in seconds)\n",
    "        grid_size: The 2D topomap's size (H, W)\n",
    "        n_time_slices: Number of snapshots to take between t0 and t1\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, epochs, time_window=(0.1, 0.4), grid_size=32, n_time_slices=5):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.times = epochs.times\n",
    "        self.info  = epochs.info\n",
    "        self.grid_size     = grid_size\n",
    "        self.n_time_slices = n_time_slices\n",
    "        \n",
    "        # Get indices for starting and ending time of interested interval\n",
    "        t0, t1     = time_window\n",
    "        self.start = np.argmin(np.abs(self.times - t0))\n",
    "        self.end   = np.argmin(np.abs(self.times - t1))\n",
    "        \n",
    "        # Get orientations of sensors in 3D space and use first two components only (x,y)\n",
    "        positions_3d = np.array([ch['loc'][:3] for ch in self.info['chs']])\n",
    "        self.pos2d = positions_3d[:, :2]  \n",
    "        \n",
    "        # Prepare grid for interpolated topomap\n",
    "        self.grid_x, self.grid_y = np.meshgrid(\n",
    "            np.linspace(self.pos2d[:,0].min(), self.pos2d[:,0].max(), self.grid_size),\n",
    "            np.linspace(self.pos2d[:,1].min(), self.pos2d[:,1].max(), self.grid_size)\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        trial = self.X[idx]  # (C_channels, T_timepoints)\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        # Select evenly-spaced time slices\n",
    "        slice_times = np.linspace(self.start, self.end-1, self.n_time_slices).astype(int)\n",
    "        topo_imgs = []\n",
    "        \n",
    "        for slice_t in slice_times:\n",
    "            values = trial[:, slice_t]  # sensor readings at time slice_t for C_channels (C_channels,)\n",
    "            topo = griddata(\n",
    "                self.pos2d, values,\n",
    "                (self.grid_x, self.grid_y),\n",
    "                method='cubic',\n",
    "                fill_value=0.0\n",
    "            )\n",
    "            topo_imgs.append(topo)\n",
    "        \n",
    "        topo_imgs = np.stack(topo_imgs, axis=0)  # (n_time_slices, H, W)\n",
    "        return torch.tensor(topo_imgs, dtype=torch.float32), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6923c9c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T03:22:35.776235Z",
     "iopub.status.busy": "2025-11-20T03:22:35.775899Z",
     "iopub.status.idle": "2025-11-20T03:22:35.781994Z",
     "shell.execute_reply": "2025-11-20T03:22:35.781463Z"
    },
    "papermill": {
     "duration": 0.00958,
     "end_time": "2025-11-20T03:22:35.782911",
     "exception": false,
     "start_time": "2025-11-20T03:22:35.773331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_channels=N_TIME_SLICES, hidden_channels=32, dropout_p=.2, n_classes=10):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU())\n",
    "            \n",
    "        def linear_block(in_dim, out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(in_dim, out_dim, bias=False),\n",
    "                nn.BatchNorm1d(out_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_p))\n",
    "            \n",
    "        self.conv = nn.Sequential(\n",
    "            conv_block(in_channels, hidden_channels),\n",
    "            conv_block(hidden_channels, 2*hidden_channels),\n",
    "            nn.MaxPool2d(2),\n",
    "            conv_block(2*hidden_channels, 3*hidden_channels),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, GRID_SIZE, GRID_SIZE)\n",
    "            out = self.conv(dummy)\n",
    "            self.flat_size = out.view(1, -1).size(1)\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            linear_block(self.flat_size, 256),\n",
    "            linear_block(256, 64),\n",
    "            nn.Linear(64, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.conv(x)\n",
    "        o = o.view(o.size(0), -1)\n",
    "        return self.classifier(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "173f330d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T03:22:35.787840Z",
     "iopub.status.busy": "2025-11-20T03:22:35.787647Z",
     "iopub.status.idle": "2025-11-20T03:22:35.791648Z",
     "shell.execute_reply": "2025-11-20T03:22:35.791162Z"
    },
    "papermill": {
     "duration": 0.007682,
     "end_time": "2025-11-20T03:22:35.792702",
     "exception": false,
     "start_time": "2025-11-20T03:22:35.785020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_model_weights(model):\n",
    "    for module in model.modules():\n",
    "        ## Linear and Convolution \n",
    "        if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        ## Batchnorm \n",
    "        if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba092a0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T03:22:35.797965Z",
     "iopub.status.busy": "2025-11-20T03:22:35.797772Z",
     "iopub.status.idle": "2025-11-20T03:22:35.806807Z",
     "shell.execute_reply": "2025-11-20T03:22:35.806302Z"
    },
    "papermill": {
     "duration": 0.012876,
     "end_time": "2025-11-20T03:22:35.807809",
     "exception": false,
     "start_time": "2025-11-20T03:22:35.794933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_evaluate(model, train_loader, val_loader, epochs=20, lr=1e-3, \n",
    "                   weight_decay=.001, early_stopping_patience=10, device=\"cuda\"):\n",
    "    model.to(device)\n",
    "    optimizer    = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn      = nn.CrossEntropyLoss()\n",
    "    lr_scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=len(train_loader))\n",
    "    history = {\"train_losses\":[], \"val_losses\":[], \"train_accs\":[], \"val_accs\":[]}\n",
    "\n",
    "    min_change          = .002\n",
    "    best_val_acc        = 0.0\n",
    "    epochs_not_improved = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # -------------------- Model training -------------------- \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_acc  = 0.0\n",
    "        total      = 0.0\n",
    "        for X, y in train_loader:\n",
    "            X, y   = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            loss   = loss_fn(logits, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            ## Accumulates loss and accuracy\n",
    "            train_loss += loss.item()\n",
    "            preds       = logits.argmax(dim=1)\n",
    "            train_acc  += (preds==y).sum().item()\n",
    "            total      += y.size(0)\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc  /= total\n",
    "        \n",
    "        # -------------------- Model Validation -------------------- \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_acc  = 0.0\n",
    "        total    = 0.0\n",
    "        with torch.inference_mode():\n",
    "            for X, y in val_loader:\n",
    "                X, y  = X.to(device), y.to(device)\n",
    "\n",
    "                ## Compute loss\n",
    "                logits    = model(X)\n",
    "                loss      = loss_fn(logits, y)\n",
    "                val_loss += loss.item()\n",
    "                ## Tracks validation accuracy\n",
    "                preds    = logits.argmax(dim=1)\n",
    "                val_acc += (preds==y).sum().item()\n",
    "                total   += y.size(0)\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc  /= total\n",
    "\n",
    "        ## -------------------- Logging -------------------- \n",
    "        history[\"train_losses\"].append(train_loss)\n",
    "        history[\"val_losses\"].append(val_loss)\n",
    "        history[\"train_accs\"].append(train_acc)\n",
    "        history[\"val_accs\"].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \",\n",
    "              f\"Train Loss: {train_loss:.4f} | \",\n",
    "              f\"Val Loss: {val_loss:.4f} | \",\n",
    "              f\"Train Acc: {train_acc:.3f} | \",\n",
    "              f\"Val Acc: {val_acc:.3f}\")\n",
    "\n",
    "        # ----------------- Early Stopping -----------------\n",
    "        if val_acc - best_val_acc >= min_change:\n",
    "            best_val_acc        = val_acc\n",
    "            epochs_not_improved = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        else:\n",
    "            epochs_not_improved += 1\n",
    "            print(f\"Early Stopping Counter: {epochs_not_improved}/{early_stopping_patience}\")\n",
    "        if epochs_not_improved >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "    return history\n",
    "\n",
    "\n",
    "def predict(model, loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.inference_mode():\n",
    "        for X,_ in loader:\n",
    "            X = X.to(device)\n",
    "            all_preds.append(model(X).argmax(dim=1))\n",
    "    return torch.cat(all_preds).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f994d264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T03:22:35.812805Z",
     "iopub.status.busy": "2025-11-20T03:22:35.812603Z",
     "iopub.status.idle": "2025-11-20T03:22:35.818764Z",
     "shell.execute_reply": "2025-11-20T03:22:35.818091Z"
    },
    "papermill": {
     "duration": 0.009849,
     "end_time": "2025-11-20T03:22:35.819830",
     "exception": false,
     "start_time": "2025-11-20T03:22:35.809981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_subject_data(data_path, subject_id, need_label_map=True, data_type='localizer'):\n",
    "    \"\"\"\n",
    "    Load data for a single subject.\n",
    "    Returns:\n",
    "        X: ndarray (M_trials, C_channels, T_timepoints)\n",
    "        y: labels  (M_trials,)\n",
    "        epochs: MNE epochs object\n",
    "        label_map: dict mapping event names to codes\n",
    "    \"\"\"\n",
    "    file_path = Path(data_path) / subject_id / f\"{subject_id}_{data_type}-epo.fif\"\n",
    "    epochs    = mne.read_epochs(file_path, preload=True, verbose=False)\n",
    "    X         = epochs.get_data()\n",
    "    y         = epochs.events[:,2]-1  # ranges from [1, 10], subtracts 1 to become [0,9]\n",
    "    label_map = None\n",
    "    if need_label_map: \n",
    "        label_map = {key:value-1 for key,value in epochs.event_id.items()} # shift values down to be in range [0,9]\n",
    "    return X, y, epochs, label_map\n",
    "\n",
    "\n",
    "\n",
    "def load_all_subjects_data(data_path, need_label_map=True, data_type='localizer'):\n",
    "    \"\"\"\n",
    "    Load data for all subjects.\n",
    "    Returns:\n",
    "        X: ndarray (M_trials * num_subjects, C_channels, T_timepoints)\n",
    "        y: labels  (M_trials * num_subjects,)\n",
    "        groups: ndarray\n",
    "        label_map: dict\n",
    "    \"\"\"\n",
    "    subject_ids = os.listdir(data_path)\n",
    "    all_X, all_y, all_groups, first_epochs = [], [], [], None\n",
    "    \n",
    "    for idx, subject_id in enumerate(subject_ids):\n",
    "        X, y, epochs, label_map = load_subject_data(data_path, subject_id, need_label_map, data_type)\n",
    "        if first_epochs is None: first_epochs=epochs\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "        all_groups.append(np.full(len(y), idx))\n",
    "    \n",
    "    X = np.concatenate(all_X, axis=0) \n",
    "    y = np.concatenate(all_y, axis=0) \n",
    "    groups = np.concatenate(all_groups, axis=0)\n",
    "    return X, y, groups, first_epochs, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e8e76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T03:22:35.825024Z",
     "iopub.status.busy": "2025-11-20T03:22:35.824825Z",
     "iopub.status.idle": "2025-11-20T03:22:35.832016Z",
     "shell.execute_reply": "2025-11-20T03:22:35.831335Z"
    },
    "papermill": {
     "duration": 0.010987,
     "end_time": "2025-11-20T03:22:35.833023",
     "exception": false,
     "start_time": "2025-11-20T03:22:35.822036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_validate(data_path, n_splits=5, \n",
    "                   dataset_params=None, model_params=None, training_params=None, device='cuda'):\n",
    "    \n",
    "    if dataset_params is None:\n",
    "        dataset_params  = {'time_window': (0.1, 0.4), 'grid_size': 32, 'n_time_slices': 5}\n",
    "    if model_params is None:\n",
    "        model_params    = {'in_channels': dataset_params['n_time_slices'], 'n_classes': 10}\n",
    "    if training_params is None:\n",
    "        training_params = {'epochs': 20, 'lr': 1e-3}\n",
    "    \n",
    "    # LOAD ALL SUBJECTS\n",
    "    X, y, groups, first_epochs, _ = load_all_subjects_data(data_path, False, \"localizer\")\n",
    "    print(f\"Total trials: {len(y)} | Subjects: {len(os.listdir(data_path))} | X dimension: {X.shape}\")\n",
    "    \n",
    "    # --- GroupKFold CV ---\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n",
    "        print(f\"\\nFold {fold_idx+1}/{n_splits}\")\n",
    "\n",
    "        ## Create train and validation datasets\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val,   y_val   = X[val_idx],   y[val_idx]\n",
    "        train_data = MEGDataset(X_train, y_train, first_epochs, **dataset_params)\n",
    "        val_data   = MEGDataset(X_val, y_val, first_epochs, **dataset_params)\n",
    "        ## Create dataloaders\n",
    "        train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4, worker_init_fn=worker_init_fn)\n",
    "        val_loader   = DataLoader(val_data,   batch_size=32, shuffle=False, num_workers=4, worker_init_fn=worker_init_fn)\n",
    "\n",
    "        ## Trains model\n",
    "        model   = Model(**model_params).to(device)\n",
    "        init_model_weights(model)\n",
    "        history = train_evaluate(model, train_loader, val_loader, **training_params, device=device)\n",
    "        \n",
    "        # Evaluates model\n",
    "        model = Model(**model_params).to(device)\n",
    "        model.load_state_dict(torch.load(\"/kaggle/working/best_model.pth\"))\n",
    "        val_preds = predict(model, val_loader, device=device)\n",
    "        val_acc   = (val_preds==y_val).mean()\n",
    "        fold_scores.append(val_acc)\n",
    "        print(f\"Fold {fold_idx+1} Validation Accuracy: {val_acc:.4f}\\n\\n\")\n",
    "    \n",
    "    mean_acc, std_acc = np.mean(fold_scores), np.std(fold_scores)\n",
    "    print(f\"\\nMean Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "    return fold_scores, mean_acc, std_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f2dfbe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T03:22:35.838102Z",
     "iopub.status.busy": "2025-11-20T03:22:35.837914Z",
     "iopub.status.idle": "2025-11-20T03:22:35.844386Z",
     "shell.execute_reply": "2025-11-20T03:22:35.843666Z"
    },
    "papermill": {
     "duration": 0.010209,
     "end_time": "2025-11-20T03:22:35.845500",
     "exception": false,
     "start_time": "2025-11-20T03:22:35.835291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_predict(train_path, test_path, dataset_params=None, model_params=None,\n",
    "                         training_params=None, output_file='submission.csv', device='cuda'):\n",
    "    \n",
    "    # --- Load all training data and trains model---\n",
    "    X_train, y_train, _, first_epochs, label_map = load_all_subjects_data(train_path, True, \"localizer\")\n",
    "    train_data   = MEGDataset(X_train, y_train, first_epochs, **dataset_params)\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4, worker_init_fn=worker_init_fn)\n",
    "    \n",
    "    model = Model(**model_params).to(device)\n",
    "    history = train_evaluate(model, train_loader, train_loader, **training_params, device=device)\n",
    "    \n",
    "    # --- Predict test subjects ---\n",
    "    test_subjects = os.listdir(test_path)\n",
    "    results = []\n",
    "    \n",
    "    inverse_map = {v:k for k,v in label_map.items()}\n",
    "    \n",
    "    for subject in test_subjects:\n",
    "        X_test, _, imagine_epochs, _ = load_subject_data(test_path, subject, False, 'imagine')\n",
    "        test_data   = MEGTopographicDataset(X_test, np.zeros(len(X_test)), imagine_epochs, **dataset_params)\n",
    "        test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4, worker_init_fn=worker_init_fn)\n",
    "        \n",
    "        preds = predict(model, test_loader, device=device)\n",
    "        pred_labels = [inverse_map[pred] for pred in preds]\n",
    "        \n",
    "        for i, label in enumerate(pred_labels, start=1):\n",
    "            results.append({'ID': f\"{sub}_{i}\", 'label': label})\n",
    "    \n",
    "    submission_df = pd.DataFrame(results)\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved submission with {len(submission_df)} rows.\")\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92385d23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T03:22:35.850309Z",
     "iopub.status.busy": "2025-11-20T03:22:35.850072Z",
     "iopub.status.idle": "2025-11-20T11:03:51.491844Z",
     "shell.execute_reply": "2025-11-20T11:03:51.490651Z"
    },
    "papermill": {
     "duration": 27675.652714,
     "end_time": "2025-11-20T11:03:51.500284",
     "exception": false,
     "start_time": "2025-11-20T03:22:35.847570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trials: 7200 | Subjects: 15 | X dimension: (7200, 309, 121)\n",
      "\n",
      "Fold 1/5\n",
      "Epoch 1/20 |  Train Loss: 2.5115 |  Val Loss: 2.3445 |  Train Acc: 0.099 |  Val Acc: 0.107\n",
      "Epoch 2/20 |  Train Loss: 2.4082 |  Val Loss: 2.3289 |  Train Acc: 0.105 |  Val Acc: 0.088\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 3/20 |  Train Loss: 2.3839 |  Val Loss: 2.3216 |  Train Acc: 0.101 |  Val Acc: 0.107\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 4/20 |  Train Loss: 2.3630 |  Val Loss: 2.3255 |  Train Acc: 0.105 |  Val Acc: 0.098\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 5/20 |  Train Loss: 2.3506 |  Val Loss: 2.3105 |  Train Acc: 0.110 |  Val Acc: 0.114\n",
      "Epoch 6/20 |  Train Loss: 2.3433 |  Val Loss: 2.3130 |  Train Acc: 0.117 |  Val Acc: 0.113\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 7/20 |  Train Loss: 2.3404 |  Val Loss: 2.3086 |  Train Acc: 0.118 |  Val Acc: 0.107\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 8/20 |  Train Loss: 2.3324 |  Val Loss: 2.3076 |  Train Acc: 0.119 |  Val Acc: 0.111\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 9/20 |  Train Loss: 2.3290 |  Val Loss: 2.3143 |  Train Acc: 0.118 |  Val Acc: 0.122\n",
      "Epoch 10/20 |  Train Loss: 2.3190 |  Val Loss: 2.3250 |  Train Acc: 0.123 |  Val Acc: 0.115\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 11/20 |  Train Loss: 2.3312 |  Val Loss: 2.3165 |  Train Acc: 0.120 |  Val Acc: 0.107\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 12/20 |  Train Loss: 2.3133 |  Val Loss: 2.3126 |  Train Acc: 0.131 |  Val Acc: 0.110\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 13/20 |  Train Loss: 2.3110 |  Val Loss: 2.3116 |  Train Acc: 0.120 |  Val Acc: 0.114\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 14/20 |  Train Loss: 2.3058 |  Val Loss: 2.3058 |  Train Acc: 0.133 |  Val Acc: 0.126\n",
      "Epoch 15/20 |  Train Loss: 2.3003 |  Val Loss: 2.3218 |  Train Acc: 0.133 |  Val Acc: 0.118\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 16/20 |  Train Loss: 2.3029 |  Val Loss: 2.3262 |  Train Acc: 0.137 |  Val Acc: 0.115\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 17/20 |  Train Loss: 2.3003 |  Val Loss: 2.3144 |  Train Acc: 0.140 |  Val Acc: 0.103\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 18/20 |  Train Loss: 2.2947 |  Val Loss: 2.3162 |  Train Acc: 0.136 |  Val Acc: 0.116\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 19/20 |  Train Loss: 2.2899 |  Val Loss: 2.3196 |  Train Acc: 0.138 |  Val Acc: 0.110\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 20/20 |  Train Loss: 2.2861 |  Val Loss: 2.3304 |  Train Acc: 0.139 |  Val Acc: 0.107\n",
      "Early Stopping Counter: 6/10\n",
      "Fold 1 Validation Accuracy: 0.1264\n",
      "\n",
      "\n",
      "\n",
      "Fold 2/5\n",
      "Epoch 1/20 |  Train Loss: 2.4998 |  Val Loss: 2.3954 |  Train Acc: 0.101 |  Val Acc: 0.090\n",
      "Epoch 2/20 |  Train Loss: 2.3891 |  Val Loss: 2.3264 |  Train Acc: 0.110 |  Val Acc: 0.097\n",
      "Epoch 3/20 |  Train Loss: 2.3596 |  Val Loss: 2.3340 |  Train Acc: 0.106 |  Val Acc: 0.099\n",
      "Epoch 4/20 |  Train Loss: 2.3411 |  Val Loss: 2.3285 |  Train Acc: 0.107 |  Val Acc: 0.113\n",
      "Epoch 5/20 |  Train Loss: 2.3335 |  Val Loss: 2.3151 |  Train Acc: 0.110 |  Val Acc: 0.116\n",
      "Epoch 6/20 |  Train Loss: 2.3344 |  Val Loss: 2.3208 |  Train Acc: 0.114 |  Val Acc: 0.107\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 7/20 |  Train Loss: 2.3317 |  Val Loss: 2.3058 |  Train Acc: 0.108 |  Val Acc: 0.117\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 8/20 |  Train Loss: 2.3260 |  Val Loss: 2.3071 |  Train Acc: 0.122 |  Val Acc: 0.119\n",
      "Epoch 9/20 |  Train Loss: 2.3253 |  Val Loss: 2.3132 |  Train Acc: 0.122 |  Val Acc: 0.106\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 10/20 |  Train Loss: 2.3248 |  Val Loss: 2.3621 |  Train Acc: 0.127 |  Val Acc: 0.115\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 11/20 |  Train Loss: 2.3194 |  Val Loss: 2.3191 |  Train Acc: 0.120 |  Val Acc: 0.114\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 12/20 |  Train Loss: 2.3235 |  Val Loss: 2.3140 |  Train Acc: 0.116 |  Val Acc: 0.122\n",
      "Epoch 13/20 |  Train Loss: 2.3144 |  Val Loss: 2.3120 |  Train Acc: 0.119 |  Val Acc: 0.113\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 14/20 |  Train Loss: 2.3106 |  Val Loss: 2.3024 |  Train Acc: 0.131 |  Val Acc: 0.131\n",
      "Epoch 15/20 |  Train Loss: 2.3031 |  Val Loss: 2.3152 |  Train Acc: 0.124 |  Val Acc: 0.122\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 16/20 |  Train Loss: 2.2969 |  Val Loss: 2.3033 |  Train Acc: 0.139 |  Val Acc: 0.127\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 17/20 |  Train Loss: 2.2974 |  Val Loss: 2.3178 |  Train Acc: 0.131 |  Val Acc: 0.119\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 18/20 |  Train Loss: 2.3030 |  Val Loss: 2.3254 |  Train Acc: 0.131 |  Val Acc: 0.118\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 19/20 |  Train Loss: 2.2974 |  Val Loss: 2.3266 |  Train Acc: 0.137 |  Val Acc: 0.127\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 20/20 |  Train Loss: 2.2958 |  Val Loss: 2.3183 |  Train Acc: 0.142 |  Val Acc: 0.127\n",
      "Early Stopping Counter: 6/10\n",
      "Fold 2 Validation Accuracy: 0.1313\n",
      "\n",
      "\n",
      "\n",
      "Fold 3/5\n",
      "Epoch 1/20 |  Train Loss: 2.4649 |  Val Loss: 2.3430 |  Train Acc: 0.104 |  Val Acc: 0.101\n",
      "Epoch 2/20 |  Train Loss: 2.4064 |  Val Loss: 2.3443 |  Train Acc: 0.100 |  Val Acc: 0.098\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 3/20 |  Train Loss: 2.3785 |  Val Loss: 2.3199 |  Train Acc: 0.106 |  Val Acc: 0.105\n",
      "Epoch 4/20 |  Train Loss: 2.3716 |  Val Loss: 2.3346 |  Train Acc: 0.113 |  Val Acc: 0.115\n",
      "Epoch 5/20 |  Train Loss: 2.3517 |  Val Loss: 2.3419 |  Train Acc: 0.123 |  Val Acc: 0.107\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 6/20 |  Train Loss: 2.3631 |  Val Loss: 2.3320 |  Train Acc: 0.112 |  Val Acc: 0.113\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 7/20 |  Train Loss: 2.3421 |  Val Loss: 2.3223 |  Train Acc: 0.125 |  Val Acc: 0.100\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 8/20 |  Train Loss: 2.3363 |  Val Loss: 2.3345 |  Train Acc: 0.121 |  Val Acc: 0.120\n",
      "Epoch 9/20 |  Train Loss: 2.3343 |  Val Loss: 2.3225 |  Train Acc: 0.127 |  Val Acc: 0.111\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 10/20 |  Train Loss: 2.3307 |  Val Loss: 2.3149 |  Train Acc: 0.132 |  Val Acc: 0.114\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 11/20 |  Train Loss: 2.3256 |  Val Loss: 2.3168 |  Train Acc: 0.134 |  Val Acc: 0.108\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 12/20 |  Train Loss: 2.3301 |  Val Loss: 2.3064 |  Train Acc: 0.125 |  Val Acc: 0.110\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 13/20 |  Train Loss: 2.3160 |  Val Loss: 2.3329 |  Train Acc: 0.123 |  Val Acc: 0.110\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 14/20 |  Train Loss: 2.3077 |  Val Loss: 2.3352 |  Train Acc: 0.140 |  Val Acc: 0.108\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 15/20 |  Train Loss: 2.3029 |  Val Loss: 2.3299 |  Train Acc: 0.137 |  Val Acc: 0.107\n",
      "Early Stopping Counter: 7/10\n",
      "Epoch 16/20 |  Train Loss: 2.3057 |  Val Loss: 2.3242 |  Train Acc: 0.142 |  Val Acc: 0.117\n",
      "Early Stopping Counter: 8/10\n",
      "Epoch 17/20 |  Train Loss: 2.3017 |  Val Loss: 2.3193 |  Train Acc: 0.149 |  Val Acc: 0.117\n",
      "Early Stopping Counter: 9/10\n",
      "Epoch 18/20 |  Train Loss: 2.2966 |  Val Loss: 2.3254 |  Train Acc: 0.149 |  Val Acc: 0.116\n",
      "Early Stopping Counter: 10/10\n",
      "Early stopping triggered at epoch 18\n",
      "Fold 3 Validation Accuracy: 0.1201\n",
      "\n",
      "\n",
      "\n",
      "Fold 4/5\n",
      "Epoch 1/20 |  Train Loss: 2.4833 |  Val Loss: 2.3112 |  Train Acc: 0.100 |  Val Acc: 0.100\n",
      "Epoch 2/20 |  Train Loss: 2.4076 |  Val Loss: 2.3025 |  Train Acc: 0.099 |  Val Acc: 0.103\n",
      "Epoch 3/20 |  Train Loss: 2.3799 |  Val Loss: 2.3022 |  Train Acc: 0.098 |  Val Acc: 0.113\n",
      "Epoch 4/20 |  Train Loss: 2.3730 |  Val Loss: 2.3013 |  Train Acc: 0.099 |  Val Acc: 0.113\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 5/20 |  Train Loss: 2.3643 |  Val Loss: 2.3070 |  Train Acc: 0.109 |  Val Acc: 0.110\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 6/20 |  Train Loss: 2.3601 |  Val Loss: 2.3017 |  Train Acc: 0.113 |  Val Acc: 0.111\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 7/20 |  Train Loss: 2.3436 |  Val Loss: 2.2972 |  Train Acc: 0.104 |  Val Acc: 0.110\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 8/20 |  Train Loss: 2.3469 |  Val Loss: 2.3015 |  Train Acc: 0.112 |  Val Acc: 0.115\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 9/20 |  Train Loss: 2.3307 |  Val Loss: 2.2981 |  Train Acc: 0.113 |  Val Acc: 0.136\n",
      "Epoch 10/20 |  Train Loss: 2.3389 |  Val Loss: 2.2941 |  Train Acc: 0.119 |  Val Acc: 0.119\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 11/20 |  Train Loss: 2.3348 |  Val Loss: 2.2970 |  Train Acc: 0.119 |  Val Acc: 0.118\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 12/20 |  Train Loss: 2.3257 |  Val Loss: 2.2938 |  Train Acc: 0.115 |  Val Acc: 0.133\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 13/20 |  Train Loss: 2.3254 |  Val Loss: 2.2956 |  Train Acc: 0.121 |  Val Acc: 0.131\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 14/20 |  Train Loss: 2.3161 |  Val Loss: 2.2894 |  Train Acc: 0.126 |  Val Acc: 0.124\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 15/20 |  Train Loss: 2.3202 |  Val Loss: 2.2943 |  Train Acc: 0.123 |  Val Acc: 0.121\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 16/20 |  Train Loss: 2.3140 |  Val Loss: 2.2930 |  Train Acc: 0.123 |  Val Acc: 0.124\n",
      "Early Stopping Counter: 7/10\n",
      "Epoch 17/20 |  Train Loss: 2.3100 |  Val Loss: 2.2937 |  Train Acc: 0.130 |  Val Acc: 0.115\n",
      "Early Stopping Counter: 8/10\n",
      "Epoch 18/20 |  Train Loss: 2.3092 |  Val Loss: 2.2955 |  Train Acc: 0.133 |  Val Acc: 0.112\n",
      "Early Stopping Counter: 9/10\n",
      "Epoch 19/20 |  Train Loss: 2.3071 |  Val Loss: 2.2947 |  Train Acc: 0.135 |  Val Acc: 0.125\n",
      "Early Stopping Counter: 10/10\n",
      "Early stopping triggered at epoch 19\n",
      "Fold 4 Validation Accuracy: 0.1361\n",
      "\n",
      "\n",
      "\n",
      "Fold 5/5\n",
      "Epoch 1/20 |  Train Loss: 2.4882 |  Val Loss: 2.3307 |  Train Acc: 0.102 |  Val Acc: 0.109\n",
      "Epoch 2/20 |  Train Loss: 2.4033 |  Val Loss: 2.3149 |  Train Acc: 0.104 |  Val Acc: 0.108\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 3/20 |  Train Loss: 2.3884 |  Val Loss: 2.3061 |  Train Acc: 0.110 |  Val Acc: 0.100\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 4/20 |  Train Loss: 2.3807 |  Val Loss: 2.3037 |  Train Acc: 0.108 |  Val Acc: 0.107\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 5/20 |  Train Loss: 2.3592 |  Val Loss: 2.2988 |  Train Acc: 0.113 |  Val Acc: 0.104\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 6/20 |  Train Loss: 2.3538 |  Val Loss: 2.2981 |  Train Acc: 0.113 |  Val Acc: 0.107\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 7/20 |  Train Loss: 2.3462 |  Val Loss: 2.3000 |  Train Acc: 0.117 |  Val Acc: 0.109\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 8/20 |  Train Loss: 2.3340 |  Val Loss: 2.3004 |  Train Acc: 0.120 |  Val Acc: 0.111\n",
      "Epoch 9/20 |  Train Loss: 2.3340 |  Val Loss: 2.3068 |  Train Acc: 0.122 |  Val Acc: 0.101\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 10/20 |  Train Loss: 2.3495 |  Val Loss: 2.3039 |  Train Acc: 0.112 |  Val Acc: 0.108\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 11/20 |  Train Loss: 2.3390 |  Val Loss: 2.3047 |  Train Acc: 0.120 |  Val Acc: 0.105\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 12/20 |  Train Loss: 2.3418 |  Val Loss: 2.3019 |  Train Acc: 0.119 |  Val Acc: 0.120\n",
      "Epoch 13/20 |  Train Loss: 2.3317 |  Val Loss: 2.3031 |  Train Acc: 0.123 |  Val Acc: 0.101\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 14/20 |  Train Loss: 2.3390 |  Val Loss: 2.3023 |  Train Acc: 0.125 |  Val Acc: 0.117\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 15/20 |  Train Loss: 2.3165 |  Val Loss: 2.3016 |  Train Acc: 0.131 |  Val Acc: 0.113\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 16/20 |  Train Loss: 2.3191 |  Val Loss: 2.3108 |  Train Acc: 0.136 |  Val Acc: 0.113\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 17/20 |  Train Loss: 2.3100 |  Val Loss: 2.3114 |  Train Acc: 0.141 |  Val Acc: 0.112\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 18/20 |  Train Loss: 2.3106 |  Val Loss: 2.3082 |  Train Acc: 0.132 |  Val Acc: 0.111\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 19/20 |  Train Loss: 2.3104 |  Val Loss: 2.2997 |  Train Acc: 0.128 |  Val Acc: 0.113\n",
      "Early Stopping Counter: 7/10\n",
      "Epoch 20/20 |  Train Loss: 2.3079 |  Val Loss: 2.3039 |  Train Acc: 0.134 |  Val Acc: 0.115\n",
      "Early Stopping Counter: 8/10\n",
      "Fold 5 Validation Accuracy: 0.1201\n",
      "\n",
      "\n",
      "\n",
      "Mean Accuracy: 0.1268 ± 0.0063\n"
     ]
    }
   ],
   "source": [
    "dataset_params  = {'time_window':TIME_WINDOW, 'grid_size':GRID_SIZE, 'n_time_slices':N_TIME_SLICES}\n",
    "model_params    = {'in_channels':dataset_params['n_time_slices'], 'n_classes':10}\n",
    "training_params = {'epochs':EPOCHS, 'lr':LEARNING_RATE}\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores, mean_acc, std_acc = cross_validate(\n",
    "    '/kaggle/input/the-imagine-decoding-challenge/train/train', \n",
    "    n_splits=5, \n",
    "    dataset_params=dataset_params,\n",
    "    model_params=model_params,\n",
    "    training_params=training_params,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "# Train on all & predict test\n",
    "# submission = train_and_predict(\n",
    "#     '/kaggle/input/the-imagine-decoding-challenge/train/train', \n",
    "#     '/kaggle/input/the-imagine-decoding-challenge/test/test', \n",
    "#     dataset_params=dataset_params,\n",
    "#     model_params=model_params,\n",
    "#     training_params=training_params,\n",
    "#     output_file='submission.csv',\n",
    "#     device='cpu'\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14107246,
     "sourceId": 117619,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27692.065461,
   "end_time": "2025-11-20T11:03:54.586408",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-20T03:22:22.520947",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
