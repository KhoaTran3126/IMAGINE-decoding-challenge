{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e123ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T21:07:18.665122Z",
     "iopub.status.busy": "2025-11-20T21:07:18.664788Z",
     "iopub.status.idle": "2025-11-20T21:07:28.039555Z",
     "shell.execute_reply": "2025-11-20T21:07:28.038698Z"
    },
    "papermill": {
     "duration": 9.381647,
     "end_time": "2025-11-20T21:07:28.041243",
     "exception": false,
     "start_time": "2025-11-20T21:07:18.659596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sea\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import joblib \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from mne.viz.topomap import _prepare_topomap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d80cafb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T21:07:28.048195Z",
     "iopub.status.busy": "2025-11-20T21:07:28.047803Z",
     "iopub.status.idle": "2025-11-20T21:07:28.051892Z",
     "shell.execute_reply": "2025-11-20T21:07:28.051114Z"
    },
    "papermill": {
     "duration": 0.008677,
     "end_time": "2025-11-20T21:07:28.053012",
     "exception": false,
     "start_time": "2025-11-20T21:07:28.044335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 3126\n",
    "EPOCHS = 50\n",
    "PCA_COMPONENTS = 25\n",
    "LEARNING_RATE = 7.5e-4\n",
    "WEIGHT_DECAY = 7.5e-3\n",
    "EARLY_STOPPING_PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de5bbd61",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-11-20T21:07:28.059167Z",
     "iopub.status.busy": "2025-11-20T21:07:28.058789Z",
     "iopub.status.idle": "2025-11-20T21:07:28.068033Z",
     "shell.execute_reply": "2025-11-20T21:07:28.067454Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.013507,
     "end_time": "2025-11-20T21:07:28.069185",
     "exception": false,
     "start_time": "2025-11-20T21:07:28.055678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)               \n",
    "    np.random.seed(seed)            \n",
    "    torch.manual_seed(seed)         \n",
    "    torch.cuda.manual_seed(seed)    \n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051ace8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T21:07:28.075020Z",
     "iopub.status.busy": "2025-11-20T21:07:28.074809Z",
     "iopub.status.idle": "2025-11-20T21:07:28.082871Z",
     "shell.execute_reply": "2025-11-20T21:07:28.082102Z"
    },
    "papermill": {
     "duration": 0.012223,
     "end_time": "2025-11-20T21:07:28.084013",
     "exception": false,
     "start_time": "2025-11-20T21:07:28.071790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PCADataset(Dataset):\n",
    "    def __init__(self, X, y, scaler=None, pca=None, augment=False, pca_components=PCA_COMPONENTS):\n",
    "        \"\"\"\n",
    "        X: (trials, channels, timepoints)\n",
    "        y: labels\n",
    "        scaler: a fitted scaler object (optional). If None (for training), fit PCA on X.\n",
    "        pca: a fitted PCA object (optional). If None (for training), fit PCA on X.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.augment = augment\n",
    "        self.pca_components = pca_components\n",
    "        self.pool = nn.AdaptiveMaxPool1d(121)\n",
    "        # Use provided PCA if given, otherwise fit one\n",
    "        self.scaler = scaler if(scaler is not None) else StandardScaler()\n",
    "        self.pca    = pca if(pca is not None) else PCA(n_components=pca_components, random_state=3126)\n",
    "        self.X_new  = self.make_X_new(fit=(pca is None))\n",
    "    \n",
    "    def make_X_new(self, fit=True):\n",
    "        m_trials, c_channels, t_time = self.X.shape\n",
    "        X_reshaped = self.X.transpose(0,2,1).reshape(-1, c_channels)  # (trials*timepoints, channels)\n",
    "\n",
    "        if fit: \n",
    "            X_reshaped = self.scaler.fit_transform(X_reshaped)\n",
    "            X_new = self.pca.fit_transform(X_reshaped)\n",
    "        else:   \n",
    "            X_reshaped = self.scaler.transform(X_reshaped)\n",
    "            X_new = self.pca.transform(X_reshaped)\n",
    "        X_new = X_new.reshape(m_trials, t_time, self.pca_components).transpose(0,2,1)  # (trials, components, timepoints)\n",
    "        ## make sure time length is 121 (length of localizer trials)\n",
    "        if X_new.shape[-1] > 121:\n",
    "            X_new = torch.tensor(X_new).float()\n",
    "            X_new = self.pool(X_new).numpy()\n",
    "        return X_new\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        trial = self.X_new[idx]\n",
    "        label = self.y[idx]     \n",
    "\n",
    "        if self.augment:\n",
    "            noise_std = np.random.uniform(0.95, 1.35)\n",
    "            trial    += np.random.normal(0, noise_std, trial.shape)\n",
    "        return torch.tensor(trial, dtype=torch.float32), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5521befc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T21:07:28.090158Z",
     "iopub.status.busy": "2025-11-20T21:07:28.089677Z",
     "iopub.status.idle": "2025-11-20T21:07:28.096017Z",
     "shell.execute_reply": "2025-11-20T21:07:28.095459Z"
    },
    "papermill": {
     "duration": 0.010536,
     "end_time": "2025-11-20T21:07:28.097054",
     "exception": false,
     "start_time": "2025-11-20T21:07:28.086518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_channels=PCA_COMPONENTS, hidden_channels=64, dropout_p=.25, n_classes=10):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU())\n",
    "            \n",
    "        def linear_block(in_dim, out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(in_dim, out_dim, bias=False),\n",
    "                nn.BatchNorm1d(out_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_p))\n",
    "            \n",
    "        self.conv = nn.Sequential(\n",
    "            conv_block(in_channels, hidden_channels),\n",
    "            nn.Dropout(dropout_p),\n",
    "            conv_block(hidden_channels, 2*hidden_channels),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(dropout_p),\n",
    "            conv_block(2*hidden_channels, 4*hidden_channels),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(dropout_p)\n",
    "        )\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     dummy = torch.zeros(1, in_channels, GRID_SIZE, GRID_SIZE)\n",
    "        #     out = self.conv(dummy)\n",
    "        #     self.flat_size = out.view(1, -1).size(1)\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            linear_block(256*30, 256),\n",
    "            linear_block(256, 64),\n",
    "            linear_block(64, 16),\n",
    "            nn.Linear(16, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.conv(x)\n",
    "        o = o.view(o.size(0), -1)\n",
    "        return self.classifier(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47758b10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T21:07:28.102743Z",
     "iopub.status.busy": "2025-11-20T21:07:28.102510Z",
     "iopub.status.idle": "2025-11-20T21:07:28.106941Z",
     "shell.execute_reply": "2025-11-20T21:07:28.106202Z"
    },
    "papermill": {
     "duration": 0.008453,
     "end_time": "2025-11-20T21:07:28.108094",
     "exception": false,
     "start_time": "2025-11-20T21:07:28.099641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_model_weights(model):\n",
    "    for module in model.modules():\n",
    "        ## Linear and Convolution \n",
    "        if isinstance(module, (nn.Linear, nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        ## Batchnorm \n",
    "        if isinstance(module, (nn.BatchNorm1d, nn.BatchNorm2d)):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09471a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T21:07:28.114256Z",
     "iopub.status.busy": "2025-11-20T21:07:28.113731Z",
     "iopub.status.idle": "2025-11-20T21:07:28.124039Z",
     "shell.execute_reply": "2025-11-20T21:07:28.123287Z"
    },
    "papermill": {
     "duration": 0.014568,
     "end_time": "2025-11-20T21:07:28.125207",
     "exception": false,
     "start_time": "2025-11-20T21:07:28.110639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_evaluate(model, train_loader, val_loader, save_path, epochs=EPOCHS, lr=LEARNING_RATE, \n",
    "                   weight_decay=WEIGHT_DECAY, early_stopping_patience=EARLY_STOPPING_PATIENCE, device=\"cuda\"):\n",
    "    model.to(device)\n",
    "    optimizer    = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn      = nn.CrossEntropyLoss()\n",
    "    lr_scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=len(train_loader))\n",
    "    history = {\"train_losses\":[], \"val_losses\":[], \"train_accs\":[], \"val_accs\":[]}\n",
    "\n",
    "    min_change          = .002\n",
    "    best_val_acc        = 0.0\n",
    "    epochs_not_improved = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # -------------------- Model training -------------------- \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_acc  = 0.0\n",
    "        total      = 0.0\n",
    "        for X, y in train_loader:\n",
    "            X, y   = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            loss   = loss_fn(logits, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            ## Accumulates loss and accuracy\n",
    "            train_loss += loss.item()\n",
    "            preds       = logits.argmax(dim=1)\n",
    "            train_acc  += (preds==y).sum().item()\n",
    "            total      += y.size(0)\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc  /= total\n",
    "        \n",
    "        # -------------------- Model Validation -------------------- \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_acc  = 0.0\n",
    "        total    = 0.0\n",
    "        with torch.inference_mode():\n",
    "            for X, y in val_loader:\n",
    "                X, y  = X.to(device), y.to(device)\n",
    "\n",
    "                ## Compute loss\n",
    "                logits    = model(X)\n",
    "                loss      = loss_fn(logits, y)\n",
    "                val_loss += loss.item()\n",
    "                ## Tracks validation accuracy\n",
    "                preds    = logits.argmax(dim=1)\n",
    "                val_acc += (preds==y).sum().item()\n",
    "                total   += y.size(0)\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc  /= total\n",
    "\n",
    "        ## -------------------- Logging -------------------- \n",
    "        history[\"train_losses\"].append(train_loss)\n",
    "        history[\"val_losses\"].append(val_loss)\n",
    "        history[\"train_accs\"].append(train_acc)\n",
    "        history[\"val_accs\"].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \",\n",
    "              f\"Train Loss: {train_loss:.4f} | \",\n",
    "              f\"Val Loss: {val_loss:.4f} | \",\n",
    "              f\"Train Acc: {train_acc:.3f} | \",\n",
    "              f\"Val Acc: {val_acc:.3f}\")\n",
    "\n",
    "        # ----------------- Early Stopping -----------------\n",
    "        if val_acc - best_val_acc >= min_change:\n",
    "            best_val_acc        = val_acc\n",
    "            epochs_not_improved = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        else:\n",
    "            epochs_not_improved += 1\n",
    "            print(f\"Early Stopping Counter: {epochs_not_improved}/{early_stopping_patience}\")\n",
    "        if epochs_not_improved >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "    return history\n",
    "\n",
    "\n",
    "def predict(model, loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.inference_mode():\n",
    "        for X,_ in loader:\n",
    "            X = X.to(device)\n",
    "            all_preds.append(model(X).argmax(dim=1))\n",
    "    return torch.cat(all_preds).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6850ef4b",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-11-20T21:07:28.131317Z",
     "iopub.status.busy": "2025-11-20T21:07:28.130736Z",
     "iopub.status.idle": "2025-11-20T21:07:28.136980Z",
     "shell.execute_reply": "2025-11-20T21:07:28.136450Z"
    },
    "papermill": {
     "duration": 0.010348,
     "end_time": "2025-11-20T21:07:28.138098",
     "exception": false,
     "start_time": "2025-11-20T21:07:28.127750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_subject_data(data_path, subject_id, need_label_map=True, data_type='localizer'):\n",
    "    \"\"\"\n",
    "    Load data for a single subject.\n",
    "    Returns:\n",
    "        X: ndarray (M_trials, C_channels, T_timepoints)\n",
    "        y: labels  (M_trials,)\n",
    "        epochs: MNE epochs object\n",
    "        label_map: dict mapping event names to codes\n",
    "    \"\"\"\n",
    "    file_path = Path(data_path) / subject_id / f\"{subject_id}_{data_type}-epo.fif\"\n",
    "    epochs    = mne.read_epochs(file_path, preload=True, verbose=False)\n",
    "    X         = epochs.get_data()\n",
    "    y         = epochs.events[:,2]-1  # ranges from [1, 10], subtracts 1 to become [0,9]\n",
    "    label_map = None\n",
    "    if need_label_map: \n",
    "        label_map = {key:value-1 for key,value in epochs.event_id.items()} # shift values down to be in range [0,9]\n",
    "    return X, y, epochs, label_map\n",
    "\n",
    "\n",
    "\n",
    "def load_all_subjects_data(data_path, need_label_map=True, data_type='localizer'):\n",
    "    \"\"\"\n",
    "    Load data for all subjects.\n",
    "    Returns:\n",
    "        X: ndarray (M_trials * num_subjects, C_channels, T_timepoints)\n",
    "        y: labels  (M_trials * num_subjects,)\n",
    "        groups: ndarray\n",
    "        label_map: dict\n",
    "    \"\"\"\n",
    "    subject_ids = os.listdir(data_path)\n",
    "    all_X, all_y, all_groups, first_epochs = [], [], [], None\n",
    "    \n",
    "    for idx, subject_id in enumerate(subject_ids):\n",
    "        X, y, epochs, label_map = load_subject_data(data_path, subject_id, need_label_map, data_type)\n",
    "        if first_epochs is None: first_epochs=epochs\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "        all_groups.append(np.full(len(y), idx))\n",
    "    \n",
    "    X = np.concatenate(all_X, axis=0) \n",
    "    y = np.concatenate(all_y, axis=0) \n",
    "    groups = np.concatenate(all_groups, axis=0)\n",
    "    return X, y, groups, first_epochs, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d001ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T21:07:28.143671Z",
     "iopub.status.busy": "2025-11-20T21:07:28.143467Z",
     "iopub.status.idle": "2025-11-20T21:07:28.150786Z",
     "shell.execute_reply": "2025-11-20T21:07:28.150147Z"
    },
    "papermill": {
     "duration": 0.011371,
     "end_time": "2025-11-20T21:07:28.151825",
     "exception": false,
     "start_time": "2025-11-20T21:07:28.140454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_validate(data_path, n_splits=5, \n",
    "                   dataset_params=None, model_params=None, training_params=None, device='cuda'):\n",
    "    \n",
    "    # if dataset_params is None:\n",
    "    #     dataset_params  = {'time_window': (0.1, 0.4), 'grid_size': 32, 'n_time_slices': 5}\n",
    "    if model_params is None:\n",
    "        model_params    = {'in_channels': PCA_COMPONENTS, 'n_classes': 10}\n",
    "    if training_params is None:\n",
    "        training_params = {'epochs': 20, 'lr': 1e-3}\n",
    "    \n",
    "    # LOAD ALL SUBJECTS\n",
    "    X, y, groups, first_epochs, _ = load_all_subjects_data(data_path, False, \"localizer\")\n",
    "    print(f\"Total trials: {len(y)} | Subjects: {len(os.listdir(data_path))} | X dimension: {X.shape}\")\n",
    "    \n",
    "    # --- GroupKFold CV ---\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n",
    "        print(f\"\\nFold {fold_idx+1}/{n_splits}\")\n",
    "\n",
    "        ## Create train and validation datasets and loaders\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val,   y_val   = X[val_idx],   y[val_idx]\n",
    "        train_data   = PCADataset(X_train, y_train, augment=True)\n",
    "        val_data     = PCADataset(X_val, y_val, train_data.scaler, train_data.pca, augment=False)\n",
    "        train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4, worker_init_fn=worker_init_fn)\n",
    "        val_loader   = DataLoader(val_data,   batch_size=32, shuffle=False, num_workers=4, worker_init_fn=worker_init_fn)\n",
    "\n",
    "        ## Trains model\n",
    "        save_path = f\"/kaggle/working/best_model_fold_{fold_idx+1}.pth\"\n",
    "        model     = Model(**model_params).to(device)\n",
    "        init_model_weights(model)\n",
    "        history   = train_evaluate(model, train_loader, val_loader, save_path, **training_params, device=device)\n",
    "        \n",
    "        # Evaluates model\n",
    "        model = Model(**model_params).to(device)\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "        val_preds = predict(model, val_loader, device=device)\n",
    "        val_acc   = (val_preds==y_val).mean()\n",
    "        fold_scores.append(val_acc)\n",
    "        print(f\"Fold {fold_idx+1} Validation Accuracy: {val_acc:.4f}\\n\\n\")\n",
    "    \n",
    "    mean_acc, std_acc = np.mean(fold_scores), np.std(fold_scores)\n",
    "    print(f\"\\nMean Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "    return fold_scores, mean_acc, std_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e560865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T21:07:28.157193Z",
     "iopub.status.busy": "2025-11-20T21:07:28.156988Z",
     "iopub.status.idle": "2025-11-20T21:14:33.714623Z",
     "shell.execute_reply": "2025-11-20T21:14:33.713693Z"
    },
    "papermill": {
     "duration": 425.561701,
     "end_time": "2025-11-20T21:14:33.715836",
     "exception": false,
     "start_time": "2025-11-20T21:07:28.154135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trials: 7200 | Subjects: 15 | X dimension: (7200, 309, 121)\n",
      "\n",
      "Fold 1/5\n",
      "Epoch 1/50 |  Train Loss: 2.6514 |  Val Loss: 2.4004 |  Train Acc: 0.102 |  Val Acc: 0.100\n",
      "Epoch 2/50 |  Train Loss: 2.4425 |  Val Loss: 2.3380 |  Train Acc: 0.105 |  Val Acc: 0.101\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 3/50 |  Train Loss: 2.3766 |  Val Loss: 2.3139 |  Train Acc: 0.109 |  Val Acc: 0.093\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 4/50 |  Train Loss: 2.3525 |  Val Loss: 2.3048 |  Train Acc: 0.119 |  Val Acc: 0.099\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 5/50 |  Train Loss: 2.3211 |  Val Loss: 2.3039 |  Train Acc: 0.126 |  Val Acc: 0.114\n",
      "Epoch 6/50 |  Train Loss: 2.3131 |  Val Loss: 2.3103 |  Train Acc: 0.125 |  Val Acc: 0.108\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 7/50 |  Train Loss: 2.2903 |  Val Loss: 2.3137 |  Train Acc: 0.143 |  Val Acc: 0.110\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 8/50 |  Train Loss: 2.2813 |  Val Loss: 2.3054 |  Train Acc: 0.143 |  Val Acc: 0.110\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 9/50 |  Train Loss: 2.2627 |  Val Loss: 2.3025 |  Train Acc: 0.157 |  Val Acc: 0.120\n",
      "Epoch 10/50 |  Train Loss: 2.2445 |  Val Loss: 2.2996 |  Train Acc: 0.164 |  Val Acc: 0.116\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 11/50 |  Train Loss: 2.2333 |  Val Loss: 2.3119 |  Train Acc: 0.172 |  Val Acc: 0.125\n",
      "Epoch 12/50 |  Train Loss: 2.2095 |  Val Loss: 2.3110 |  Train Acc: 0.182 |  Val Acc: 0.126\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 13/50 |  Train Loss: 2.1922 |  Val Loss: 2.3017 |  Train Acc: 0.193 |  Val Acc: 0.143\n",
      "Epoch 14/50 |  Train Loss: 2.1803 |  Val Loss: 2.3061 |  Train Acc: 0.206 |  Val Acc: 0.140\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 15/50 |  Train Loss: 2.1649 |  Val Loss: 2.2864 |  Train Acc: 0.206 |  Val Acc: 0.134\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 16/50 |  Train Loss: 2.1574 |  Val Loss: 2.3133 |  Train Acc: 0.219 |  Val Acc: 0.128\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 17/50 |  Train Loss: 2.1259 |  Val Loss: 2.3319 |  Train Acc: 0.228 |  Val Acc: 0.131\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 18/50 |  Train Loss: 2.1102 |  Val Loss: 2.3168 |  Train Acc: 0.234 |  Val Acc: 0.138\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 19/50 |  Train Loss: 2.1075 |  Val Loss: 2.3000 |  Train Acc: 0.246 |  Val Acc: 0.146\n",
      "Epoch 20/50 |  Train Loss: 2.0755 |  Val Loss: 2.3223 |  Train Acc: 0.257 |  Val Acc: 0.152\n",
      "Epoch 21/50 |  Train Loss: 2.0642 |  Val Loss: 2.3150 |  Train Acc: 0.251 |  Val Acc: 0.142\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 22/50 |  Train Loss: 2.0504 |  Val Loss: 2.3231 |  Train Acc: 0.264 |  Val Acc: 0.126\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 23/50 |  Train Loss: 2.0199 |  Val Loss: 2.3208 |  Train Acc: 0.281 |  Val Acc: 0.133\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 24/50 |  Train Loss: 2.0156 |  Val Loss: 2.3048 |  Train Acc: 0.285 |  Val Acc: 0.150\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 25/50 |  Train Loss: 2.0102 |  Val Loss: 2.3064 |  Train Acc: 0.281 |  Val Acc: 0.142\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 26/50 |  Train Loss: 2.0013 |  Val Loss: 2.3050 |  Train Acc: 0.295 |  Val Acc: 0.139\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 27/50 |  Train Loss: 1.9766 |  Val Loss: 2.3165 |  Train Acc: 0.300 |  Val Acc: 0.154\n",
      "Epoch 28/50 |  Train Loss: 1.9627 |  Val Loss: 2.3176 |  Train Acc: 0.303 |  Val Acc: 0.145\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 29/50 |  Train Loss: 1.9484 |  Val Loss: 2.3169 |  Train Acc: 0.316 |  Val Acc: 0.149\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 30/50 |  Train Loss: 1.9162 |  Val Loss: 2.3301 |  Train Acc: 0.322 |  Val Acc: 0.147\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 31/50 |  Train Loss: 1.9120 |  Val Loss: 2.3267 |  Train Acc: 0.327 |  Val Acc: 0.140\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 32/50 |  Train Loss: 1.9013 |  Val Loss: 2.3371 |  Train Acc: 0.339 |  Val Acc: 0.137\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 33/50 |  Train Loss: 1.8765 |  Val Loss: 2.3267 |  Train Acc: 0.341 |  Val Acc: 0.135\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 34/50 |  Train Loss: 1.8413 |  Val Loss: 2.3591 |  Train Acc: 0.359 |  Val Acc: 0.145\n",
      "Early Stopping Counter: 7/10\n",
      "Epoch 35/50 |  Train Loss: 1.8461 |  Val Loss: 2.3694 |  Train Acc: 0.351 |  Val Acc: 0.138\n",
      "Early Stopping Counter: 8/10\n",
      "Epoch 36/50 |  Train Loss: 1.8354 |  Val Loss: 2.3547 |  Train Acc: 0.355 |  Val Acc: 0.152\n",
      "Early Stopping Counter: 9/10\n",
      "Epoch 37/50 |  Train Loss: 1.8143 |  Val Loss: 2.3394 |  Train Acc: 0.366 |  Val Acc: 0.153\n",
      "Early Stopping Counter: 10/10\n",
      "Early stopping triggered at epoch 37\n",
      "Fold 1 Validation Accuracy: 0.1542\n",
      "\n",
      "\n",
      "\n",
      "Fold 2/5\n",
      "Epoch 1/50 |  Train Loss: 2.6331 |  Val Loss: 2.4125 |  Train Acc: 0.107 |  Val Acc: 0.102\n",
      "Epoch 2/50 |  Train Loss: 2.4879 |  Val Loss: 2.3541 |  Train Acc: 0.104 |  Val Acc: 0.101\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 3/50 |  Train Loss: 2.4147 |  Val Loss: 2.3176 |  Train Acc: 0.110 |  Val Acc: 0.101\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 4/50 |  Train Loss: 2.3738 |  Val Loss: 2.3131 |  Train Acc: 0.125 |  Val Acc: 0.111\n",
      "Epoch 5/50 |  Train Loss: 2.3566 |  Val Loss: 2.3025 |  Train Acc: 0.131 |  Val Acc: 0.113\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 6/50 |  Train Loss: 2.3270 |  Val Loss: 2.3027 |  Train Acc: 0.143 |  Val Acc: 0.106\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 7/50 |  Train Loss: 2.3184 |  Val Loss: 2.2996 |  Train Acc: 0.136 |  Val Acc: 0.124\n",
      "Epoch 8/50 |  Train Loss: 2.2910 |  Val Loss: 2.3131 |  Train Acc: 0.156 |  Val Acc: 0.117\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 9/50 |  Train Loss: 2.2881 |  Val Loss: 2.3088 |  Train Acc: 0.153 |  Val Acc: 0.124\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 10/50 |  Train Loss: 2.2675 |  Val Loss: 2.3062 |  Train Acc: 0.161 |  Val Acc: 0.124\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 11/50 |  Train Loss: 2.2405 |  Val Loss: 2.3058 |  Train Acc: 0.172 |  Val Acc: 0.119\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 12/50 |  Train Loss: 2.2243 |  Val Loss: 2.3110 |  Train Acc: 0.177 |  Val Acc: 0.140\n",
      "Epoch 13/50 |  Train Loss: 2.1982 |  Val Loss: 2.3074 |  Train Acc: 0.194 |  Val Acc: 0.131\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 14/50 |  Train Loss: 2.1687 |  Val Loss: 2.3114 |  Train Acc: 0.219 |  Val Acc: 0.144\n",
      "Epoch 15/50 |  Train Loss: 2.1717 |  Val Loss: 2.2978 |  Train Acc: 0.209 |  Val Acc: 0.142\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 16/50 |  Train Loss: 2.1497 |  Val Loss: 2.2979 |  Train Acc: 0.227 |  Val Acc: 0.151\n",
      "Epoch 17/50 |  Train Loss: 2.1305 |  Val Loss: 2.2889 |  Train Acc: 0.225 |  Val Acc: 0.152\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 18/50 |  Train Loss: 2.1135 |  Val Loss: 2.2961 |  Train Acc: 0.238 |  Val Acc: 0.148\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 19/50 |  Train Loss: 2.0853 |  Val Loss: 2.3167 |  Train Acc: 0.243 |  Val Acc: 0.147\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 20/50 |  Train Loss: 2.0929 |  Val Loss: 2.3050 |  Train Acc: 0.249 |  Val Acc: 0.158\n",
      "Epoch 21/50 |  Train Loss: 2.0699 |  Val Loss: 2.3080 |  Train Acc: 0.256 |  Val Acc: 0.144\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 22/50 |  Train Loss: 2.0568 |  Val Loss: 2.3066 |  Train Acc: 0.259 |  Val Acc: 0.159\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 23/50 |  Train Loss: 2.0405 |  Val Loss: 2.3129 |  Train Acc: 0.273 |  Val Acc: 0.153\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 24/50 |  Train Loss: 2.0315 |  Val Loss: 2.3151 |  Train Acc: 0.272 |  Val Acc: 0.156\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 25/50 |  Train Loss: 1.9937 |  Val Loss: 2.3219 |  Train Acc: 0.294 |  Val Acc: 0.147\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 26/50 |  Train Loss: 2.0107 |  Val Loss: 2.3122 |  Train Acc: 0.277 |  Val Acc: 0.147\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 27/50 |  Train Loss: 1.9884 |  Val Loss: 2.3171 |  Train Acc: 0.293 |  Val Acc: 0.150\n",
      "Early Stopping Counter: 7/10\n",
      "Epoch 28/50 |  Train Loss: 1.9734 |  Val Loss: 2.3076 |  Train Acc: 0.299 |  Val Acc: 0.156\n",
      "Early Stopping Counter: 8/10\n",
      "Epoch 29/50 |  Train Loss: 1.9533 |  Val Loss: 2.3251 |  Train Acc: 0.312 |  Val Acc: 0.154\n",
      "Early Stopping Counter: 9/10\n",
      "Epoch 30/50 |  Train Loss: 1.9460 |  Val Loss: 2.3248 |  Train Acc: 0.305 |  Val Acc: 0.153\n",
      "Early Stopping Counter: 10/10\n",
      "Early stopping triggered at epoch 30\n",
      "Fold 2 Validation Accuracy: 0.1583\n",
      "\n",
      "\n",
      "\n",
      "Fold 3/5\n",
      "Epoch 1/50 |  Train Loss: 2.5949 |  Val Loss: 2.3711 |  Train Acc: 0.105 |  Val Acc: 0.099\n",
      "Epoch 2/50 |  Train Loss: 2.4516 |  Val Loss: 2.4023 |  Train Acc: 0.109 |  Val Acc: 0.089\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 3/50 |  Train Loss: 2.3870 |  Val Loss: 2.3874 |  Train Acc: 0.119 |  Val Acc: 0.097\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 4/50 |  Train Loss: 2.3664 |  Val Loss: 2.3425 |  Train Acc: 0.112 |  Val Acc: 0.102\n",
      "Epoch 5/50 |  Train Loss: 2.3333 |  Val Loss: 2.3249 |  Train Acc: 0.126 |  Val Acc: 0.104\n",
      "Epoch 6/50 |  Train Loss: 2.3199 |  Val Loss: 2.3305 |  Train Acc: 0.133 |  Val Acc: 0.109\n",
      "Epoch 7/50 |  Train Loss: 2.3085 |  Val Loss: 2.3122 |  Train Acc: 0.143 |  Val Acc: 0.101\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 8/50 |  Train Loss: 2.2838 |  Val Loss: 2.3182 |  Train Acc: 0.152 |  Val Acc: 0.117\n",
      "Epoch 9/50 |  Train Loss: 2.2665 |  Val Loss: 2.3157 |  Train Acc: 0.158 |  Val Acc: 0.111\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 10/50 |  Train Loss: 2.2465 |  Val Loss: 2.3142 |  Train Acc: 0.183 |  Val Acc: 0.119\n",
      "Epoch 11/50 |  Train Loss: 2.2233 |  Val Loss: 2.3027 |  Train Acc: 0.171 |  Val Acc: 0.128\n",
      "Epoch 12/50 |  Train Loss: 2.2047 |  Val Loss: 2.3123 |  Train Acc: 0.186 |  Val Acc: 0.122\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 13/50 |  Train Loss: 2.1845 |  Val Loss: 2.3072 |  Train Acc: 0.192 |  Val Acc: 0.112\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 14/50 |  Train Loss: 2.1694 |  Val Loss: 2.3002 |  Train Acc: 0.202 |  Val Acc: 0.126\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 15/50 |  Train Loss: 2.1526 |  Val Loss: 2.2938 |  Train Acc: 0.215 |  Val Acc: 0.131\n",
      "Epoch 16/50 |  Train Loss: 2.1292 |  Val Loss: 2.2971 |  Train Acc: 0.230 |  Val Acc: 0.126\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 17/50 |  Train Loss: 2.1194 |  Val Loss: 2.2896 |  Train Acc: 0.232 |  Val Acc: 0.130\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 18/50 |  Train Loss: 2.0984 |  Val Loss: 2.3015 |  Train Acc: 0.236 |  Val Acc: 0.139\n",
      "Epoch 19/50 |  Train Loss: 2.0779 |  Val Loss: 2.3078 |  Train Acc: 0.249 |  Val Acc: 0.135\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 20/50 |  Train Loss: 2.0598 |  Val Loss: 2.3148 |  Train Acc: 0.252 |  Val Acc: 0.128\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 21/50 |  Train Loss: 2.0282 |  Val Loss: 2.3169 |  Train Acc: 0.268 |  Val Acc: 0.132\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 22/50 |  Train Loss: 2.0280 |  Val Loss: 2.3336 |  Train Acc: 0.273 |  Val Acc: 0.131\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 23/50 |  Train Loss: 2.0203 |  Val Loss: 2.3320 |  Train Acc: 0.281 |  Val Acc: 0.140\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 24/50 |  Train Loss: 2.0064 |  Val Loss: 2.3299 |  Train Acc: 0.284 |  Val Acc: 0.140\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 25/50 |  Train Loss: 1.9875 |  Val Loss: 2.3312 |  Train Acc: 0.286 |  Val Acc: 0.134\n",
      "Early Stopping Counter: 7/10\n",
      "Epoch 26/50 |  Train Loss: 1.9660 |  Val Loss: 2.3478 |  Train Acc: 0.293 |  Val Acc: 0.124\n",
      "Early Stopping Counter: 8/10\n",
      "Epoch 27/50 |  Train Loss: 1.9431 |  Val Loss: 2.3762 |  Train Acc: 0.307 |  Val Acc: 0.132\n",
      "Early Stopping Counter: 9/10\n",
      "Epoch 28/50 |  Train Loss: 1.9267 |  Val Loss: 2.3764 |  Train Acc: 0.315 |  Val Acc: 0.124\n",
      "Early Stopping Counter: 10/10\n",
      "Early stopping triggered at epoch 28\n",
      "Fold 3 Validation Accuracy: 0.1389\n",
      "\n",
      "\n",
      "\n",
      "Fold 4/5\n",
      "Epoch 1/50 |  Train Loss: 2.5785 |  Val Loss: 2.3492 |  Train Acc: 0.090 |  Val Acc: 0.091\n",
      "Epoch 2/50 |  Train Loss: 2.4135 |  Val Loss: 2.3226 |  Train Acc: 0.111 |  Val Acc: 0.100\n",
      "Epoch 3/50 |  Train Loss: 2.3679 |  Val Loss: 2.3097 |  Train Acc: 0.111 |  Val Acc: 0.099\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 4/50 |  Train Loss: 2.3484 |  Val Loss: 2.3035 |  Train Acc: 0.116 |  Val Acc: 0.113\n",
      "Epoch 5/50 |  Train Loss: 2.3302 |  Val Loss: 2.2988 |  Train Acc: 0.116 |  Val Acc: 0.110\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 6/50 |  Train Loss: 2.3053 |  Val Loss: 2.2963 |  Train Acc: 0.130 |  Val Acc: 0.144\n",
      "Epoch 7/50 |  Train Loss: 2.2985 |  Val Loss: 2.2964 |  Train Acc: 0.135 |  Val Acc: 0.116\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 8/50 |  Train Loss: 2.2844 |  Val Loss: 2.2927 |  Train Acc: 0.139 |  Val Acc: 0.126\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 9/50 |  Train Loss: 2.2667 |  Val Loss: 2.2828 |  Train Acc: 0.151 |  Val Acc: 0.131\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 10/50 |  Train Loss: 2.2628 |  Val Loss: 2.2896 |  Train Acc: 0.148 |  Val Acc: 0.122\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 11/50 |  Train Loss: 2.2518 |  Val Loss: 2.2731 |  Train Acc: 0.157 |  Val Acc: 0.153\n",
      "Epoch 12/50 |  Train Loss: 2.2397 |  Val Loss: 2.2692 |  Train Acc: 0.169 |  Val Acc: 0.154\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 13/50 |  Train Loss: 2.2182 |  Val Loss: 2.2656 |  Train Acc: 0.177 |  Val Acc: 0.167\n",
      "Epoch 14/50 |  Train Loss: 2.2117 |  Val Loss: 2.2603 |  Train Acc: 0.177 |  Val Acc: 0.163\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 15/50 |  Train Loss: 2.2052 |  Val Loss: 2.2592 |  Train Acc: 0.182 |  Val Acc: 0.168\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 16/50 |  Train Loss: 2.1913 |  Val Loss: 2.2558 |  Train Acc: 0.195 |  Val Acc: 0.175\n",
      "Epoch 17/50 |  Train Loss: 2.1764 |  Val Loss: 2.2454 |  Train Acc: 0.198 |  Val Acc: 0.175\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 18/50 |  Train Loss: 2.1562 |  Val Loss: 2.2634 |  Train Acc: 0.207 |  Val Acc: 0.173\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 19/50 |  Train Loss: 2.1579 |  Val Loss: 2.2580 |  Train Acc: 0.211 |  Val Acc: 0.171\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 20/50 |  Train Loss: 2.1447 |  Val Loss: 2.2627 |  Train Acc: 0.215 |  Val Acc: 0.167\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 21/50 |  Train Loss: 2.1238 |  Val Loss: 2.2565 |  Train Acc: 0.222 |  Val Acc: 0.163\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 22/50 |  Train Loss: 2.1053 |  Val Loss: 2.2548 |  Train Acc: 0.235 |  Val Acc: 0.176\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 23/50 |  Train Loss: 2.0999 |  Val Loss: 2.2531 |  Train Acc: 0.240 |  Val Acc: 0.184\n",
      "Epoch 24/50 |  Train Loss: 2.0817 |  Val Loss: 2.2547 |  Train Acc: 0.255 |  Val Acc: 0.183\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 25/50 |  Train Loss: 2.0630 |  Val Loss: 2.2436 |  Train Acc: 0.261 |  Val Acc: 0.188\n",
      "Epoch 26/50 |  Train Loss: 2.0583 |  Val Loss: 2.2463 |  Train Acc: 0.252 |  Val Acc: 0.188\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 27/50 |  Train Loss: 2.0309 |  Val Loss: 2.2550 |  Train Acc: 0.277 |  Val Acc: 0.186\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 28/50 |  Train Loss: 2.0283 |  Val Loss: 2.2602 |  Train Acc: 0.268 |  Val Acc: 0.185\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 29/50 |  Train Loss: 2.0076 |  Val Loss: 2.2876 |  Train Acc: 0.280 |  Val Acc: 0.172\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 30/50 |  Train Loss: 1.9888 |  Val Loss: 2.2805 |  Train Acc: 0.295 |  Val Acc: 0.180\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 31/50 |  Train Loss: 1.9781 |  Val Loss: 2.2575 |  Train Acc: 0.299 |  Val Acc: 0.188\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 32/50 |  Train Loss: 1.9736 |  Val Loss: 2.2831 |  Train Acc: 0.295 |  Val Acc: 0.184\n",
      "Early Stopping Counter: 7/10\n",
      "Epoch 33/50 |  Train Loss: 1.9452 |  Val Loss: 2.2791 |  Train Acc: 0.308 |  Val Acc: 0.176\n",
      "Early Stopping Counter: 8/10\n",
      "Epoch 34/50 |  Train Loss: 1.9433 |  Val Loss: 2.2877 |  Train Acc: 0.309 |  Val Acc: 0.179\n",
      "Early Stopping Counter: 9/10\n",
      "Epoch 35/50 |  Train Loss: 1.9315 |  Val Loss: 2.2760 |  Train Acc: 0.315 |  Val Acc: 0.190\n",
      "Epoch 36/50 |  Train Loss: 1.9227 |  Val Loss: 2.2924 |  Train Acc: 0.323 |  Val Acc: 0.178\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 37/50 |  Train Loss: 1.8898 |  Val Loss: 2.3072 |  Train Acc: 0.331 |  Val Acc: 0.176\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 38/50 |  Train Loss: 1.8777 |  Val Loss: 2.3086 |  Train Acc: 0.342 |  Val Acc: 0.177\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 39/50 |  Train Loss: 1.8849 |  Val Loss: 2.2734 |  Train Acc: 0.331 |  Val Acc: 0.169\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 40/50 |  Train Loss: 1.8694 |  Val Loss: 2.3172 |  Train Acc: 0.340 |  Val Acc: 0.178\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 41/50 |  Train Loss: 1.8430 |  Val Loss: 2.3163 |  Train Acc: 0.347 |  Val Acc: 0.176\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 42/50 |  Train Loss: 1.8266 |  Val Loss: 2.3226 |  Train Acc: 0.353 |  Val Acc: 0.190\n",
      "Early Stopping Counter: 7/10\n",
      "Epoch 43/50 |  Train Loss: 1.8244 |  Val Loss: 2.3136 |  Train Acc: 0.367 |  Val Acc: 0.181\n",
      "Early Stopping Counter: 8/10\n",
      "Epoch 44/50 |  Train Loss: 1.7918 |  Val Loss: 2.3286 |  Train Acc: 0.373 |  Val Acc: 0.185\n",
      "Early Stopping Counter: 9/10\n",
      "Epoch 45/50 |  Train Loss: 1.7678 |  Val Loss: 2.3330 |  Train Acc: 0.374 |  Val Acc: 0.185\n",
      "Early Stopping Counter: 10/10\n",
      "Early stopping triggered at epoch 45\n",
      "Fold 4 Validation Accuracy: 0.1896\n",
      "\n",
      "\n",
      "\n",
      "Fold 5/5\n",
      "Epoch 1/50 |  Train Loss: 2.6051 |  Val Loss: 2.4318 |  Train Acc: 0.104 |  Val Acc: 0.106\n",
      "Epoch 2/50 |  Train Loss: 2.4517 |  Val Loss: 2.3414 |  Train Acc: 0.106 |  Val Acc: 0.111\n",
      "Epoch 3/50 |  Train Loss: 2.3849 |  Val Loss: 2.3152 |  Train Acc: 0.114 |  Val Acc: 0.110\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 4/50 |  Train Loss: 2.3352 |  Val Loss: 2.3048 |  Train Acc: 0.122 |  Val Acc: 0.124\n",
      "Epoch 5/50 |  Train Loss: 2.3175 |  Val Loss: 2.3008 |  Train Acc: 0.118 |  Val Acc: 0.124\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 6/50 |  Train Loss: 2.2967 |  Val Loss: 2.2968 |  Train Acc: 0.132 |  Val Acc: 0.115\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 7/50 |  Train Loss: 2.2837 |  Val Loss: 2.2989 |  Train Acc: 0.131 |  Val Acc: 0.125\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 8/50 |  Train Loss: 2.2619 |  Val Loss: 2.3001 |  Train Acc: 0.155 |  Val Acc: 0.117\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 9/50 |  Train Loss: 2.2579 |  Val Loss: 2.3073 |  Train Acc: 0.160 |  Val Acc: 0.125\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 10/50 |  Train Loss: 2.2396 |  Val Loss: 2.3023 |  Train Acc: 0.166 |  Val Acc: 0.124\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 11/50 |  Train Loss: 2.2316 |  Val Loss: 2.3045 |  Train Acc: 0.173 |  Val Acc: 0.134\n",
      "Epoch 12/50 |  Train Loss: 2.2215 |  Val Loss: 2.3032 |  Train Acc: 0.179 |  Val Acc: 0.138\n",
      "Epoch 13/50 |  Train Loss: 2.1967 |  Val Loss: 2.3068 |  Train Acc: 0.196 |  Val Acc: 0.131\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 14/50 |  Train Loss: 2.1927 |  Val Loss: 2.2933 |  Train Acc: 0.195 |  Val Acc: 0.127\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 15/50 |  Train Loss: 2.1684 |  Val Loss: 2.3009 |  Train Acc: 0.207 |  Val Acc: 0.133\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 16/50 |  Train Loss: 2.1565 |  Val Loss: 2.3008 |  Train Acc: 0.211 |  Val Acc: 0.144\n",
      "Epoch 17/50 |  Train Loss: 2.1426 |  Val Loss: 2.2878 |  Train Acc: 0.223 |  Val Acc: 0.144\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 18/50 |  Train Loss: 2.1292 |  Val Loss: 2.2958 |  Train Acc: 0.225 |  Val Acc: 0.151\n",
      "Epoch 19/50 |  Train Loss: 2.1065 |  Val Loss: 2.2957 |  Train Acc: 0.243 |  Val Acc: 0.151\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 20/50 |  Train Loss: 2.0949 |  Val Loss: 2.2979 |  Train Acc: 0.241 |  Val Acc: 0.154\n",
      "Epoch 21/50 |  Train Loss: 2.0886 |  Val Loss: 2.3041 |  Train Acc: 0.254 |  Val Acc: 0.159\n",
      "Epoch 22/50 |  Train Loss: 2.0655 |  Val Loss: 2.2942 |  Train Acc: 0.256 |  Val Acc: 0.172\n",
      "Epoch 23/50 |  Train Loss: 2.0686 |  Val Loss: 2.2998 |  Train Acc: 0.257 |  Val Acc: 0.162\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 24/50 |  Train Loss: 2.0399 |  Val Loss: 2.2881 |  Train Acc: 0.267 |  Val Acc: 0.168\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 25/50 |  Train Loss: 2.0300 |  Val Loss: 2.3000 |  Train Acc: 0.270 |  Val Acc: 0.152\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 26/50 |  Train Loss: 2.0241 |  Val Loss: 2.3115 |  Train Acc: 0.276 |  Val Acc: 0.165\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 27/50 |  Train Loss: 2.0095 |  Val Loss: 2.3185 |  Train Acc: 0.281 |  Val Acc: 0.162\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 28/50 |  Train Loss: 1.9962 |  Val Loss: 2.3176 |  Train Acc: 0.289 |  Val Acc: 0.167\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 29/50 |  Train Loss: 1.9651 |  Val Loss: 2.3126 |  Train Acc: 0.308 |  Val Acc: 0.165\n",
      "Early Stopping Counter: 7/10\n",
      "Epoch 30/50 |  Train Loss: 1.9544 |  Val Loss: 2.3167 |  Train Acc: 0.305 |  Val Acc: 0.163\n",
      "Early Stopping Counter: 8/10\n",
      "Epoch 31/50 |  Train Loss: 1.9370 |  Val Loss: 2.3206 |  Train Acc: 0.317 |  Val Acc: 0.159\n",
      "Early Stopping Counter: 9/10\n",
      "Epoch 32/50 |  Train Loss: 1.9269 |  Val Loss: 2.3365 |  Train Acc: 0.325 |  Val Acc: 0.173\n",
      "Early Stopping Counter: 10/10\n",
      "Early stopping triggered at epoch 32\n",
      "Fold 5 Validation Accuracy: 0.1715\n",
      "\n",
      "\n",
      "\n",
      "Mean Accuracy: 0.1625 ± 0.0171\n"
     ]
    }
   ],
   "source": [
    "# dataset_params  = {'time_window':TIME_WINDOW, 'grid_size':GRID_SIZE, 'n_time_slices':N_TIME_SLICES}\n",
    "model_params    = {'in_channels':PCA_COMPONENTS, 'n_classes':10}\n",
    "training_params = {'epochs':EPOCHS, 'lr':LEARNING_RATE}\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores, mean_acc, std_acc = cross_validate(\n",
    "    '/kaggle/input/the-imagine-decoding-challenge/train/train', \n",
    "    n_splits=5, \n",
    "    dataset_params=None,\n",
    "    model_params=model_params,\n",
    "    training_params=training_params,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50882b",
   "metadata": {
    "papermill": {
     "duration": 0.009417,
     "end_time": "2025-11-20T21:14:33.734866",
     "exception": false,
     "start_time": "2025-11-20T21:14:33.725449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c4f2c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T21:14:33.754783Z",
     "iopub.status.busy": "2025-11-20T21:14:33.754105Z",
     "iopub.status.idle": "2025-11-20T21:14:51.134164Z",
     "shell.execute_reply": "2025-11-20T21:14:51.133513Z"
    },
    "papermill": {
     "duration": 17.391528,
     "end_time": "2025-11-20T21:14:51.135515",
     "exception": false,
     "start_time": "2025-11-20T21:14:33.743987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " X, y, _, _, label_map = load_all_subjects_data(\"/kaggle/input/the-imagine-decoding-challenge/train/train\", True, \"imagine\")\n",
    "train_data   = PCADataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55932605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T21:14:51.155375Z",
     "iopub.status.busy": "2025-11-20T21:14:51.155153Z",
     "iopub.status.idle": "2025-11-20T21:15:11.948672Z",
     "shell.execute_reply": "2025-11-20T21:15:11.947641Z"
    },
    "papermill": {
     "duration": 20.805012,
     "end_time": "2025-11-20T21:15:11.950170",
     "exception": false,
     "start_time": "2025-11-20T21:14:51.145158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission with 680 rows.\n"
     ]
    }
   ],
   "source": [
    "test_subjects = os.listdir(\"/kaggle/input/the-imagine-decoding-challenge/test/test\")\n",
    "results = []\n",
    "\n",
    "inverse_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "for subject in test_subjects:\n",
    "    # Load test data and apply train PCA + scaler\n",
    "    X_test, _, imagine_epochs, _ = load_subject_data(\"/kaggle/input/the-imagine-decoding-challenge/test/test\", subject, False, 'imagine')\n",
    "    test_data = PCADataset(X_test, np.zeros(len(X_test)), scaler=train_data.scaler, pca=train_data.pca, augment=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4,\n",
    "                             worker_init_fn=worker_init_fn)\n",
    "\n",
    "    # Collect softmax probabilities from all folds\n",
    "    probs_all = []\n",
    "    for k in range(1, 6):\n",
    "        fold_path = f\"/kaggle/working/best_model_fold_{k}.pth\"\n",
    "        model = Model(**model_params).to(\"cuda\")\n",
    "        model.load_state_dict(torch.load(fold_path))\n",
    "        model.eval()\n",
    "        fold_probs = []\n",
    "        with torch.inference_mode():\n",
    "            for X_batch, _ in test_loader:\n",
    "                X_batch = X_batch.to(\"cuda\")\n",
    "                logits = model(X_batch)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                fold_probs.append(probs.cpu())\n",
    "        fold_probs = torch.cat(fold_probs, dim=0).numpy()\n",
    "        probs_all.append(fold_probs)\n",
    "\n",
    "    # Average probabilities across folds\n",
    "    probs_all = np.array(probs_all)            # shape: (n_folds, n_trials, n_classes)\n",
    "    avg_probs = np.mean(probs_all, axis=0)     # shape: (n_trials, n_classes)\n",
    "\n",
    "    # Take argmax to get final predicted class\n",
    "    ensemble_preds = np.argmax(avg_probs, axis=1)\n",
    "    pred_labels = [inverse_map[pred] for pred in ensemble_preds]\n",
    "\n",
    "    for i, label in enumerate(pred_labels, start=1):\n",
    "        results.append({'ID': f\"{subject}_{i}\", 'label': label})\n",
    "\n",
    "submission_df = pd.DataFrame(results)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(f\"Saved submission with {len(submission_df)} rows.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14107246,
     "sourceId": 117619,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 480.284592,
   "end_time": "2025-11-20T21:15:14.984227",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-20T21:07:14.699635",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
